{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2705f4ba",
   "metadata": {},
   "source": [
    "## 1. east text detection + pytesseract(text recognition)\n",
    "- east text detection 참고 : https://pyimagesearch.com/2018/08/20/opencv-text-detection-east-text-detector/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924b8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "\n",
    "min_confidence = 0.05\n",
    "file_name = \"test7.jpg\"\n",
    "\n",
    "east_decorator = 'frozen_east_text_detection.pb'\n",
    "\n",
    "frame_size = 320\n",
    "padding = 0.15\n",
    "\n",
    "def textRead(image):  #tessaract 이용\n",
    "    # apply Tesseract v4 to OCR \n",
    "    config = (\"-l kor+eng --oem 1 --psm 12\")\n",
    "    text = pytesseract.image_to_string(image, config=config)\n",
    "    # display the text OCR'd by Tesseract\n",
    "    print(\"OCR TEXT : {}\\n\".format(text))\n",
    "    \n",
    "    # strip out non-ASCII text (문자, 숫자만 필터링)\n",
    "    text = \"\".join([c if c.isalnum() else \"\" for c in text]).strip()\n",
    "    print(\"TEXT : {}\\n\".format(text))\n",
    "    return text\n",
    "\n",
    "def textROI(image): #east text detection 이용\n",
    "    # load the input image and grab the image dimensions\n",
    "    orig = image.copy()\n",
    "    (origH, origW) = image.shape[:2]\n",
    " \n",
    "    # set the new width and height and then determine the ratio in change\n",
    "    rW = origW / float(frame_size)\n",
    "    rH = origH / float(frame_size)\n",
    "    newW = int(origW / rH)\n",
    "    center = int(newW / 2)\n",
    "    start = center - int(frame_size / 2)\n",
    " \n",
    "    # resize the image and grab the new image dimensions\n",
    "    image = cv2.resize(image, (newW, frame_size))  \n",
    "    scale_image = image[0:frame_size, start:start+frame_size]\n",
    "    (H, W) = scale_image.shape[:2]\n",
    "\n",
    "#     cv2.imshow(\"orig\", orig)\n",
    "#     cv2.imshow(\"resize\", image)\n",
    "#     cv2.imshow(\"scale_image\", scale_image)\n",
    "    \n",
    "    # define the two output layer names for the EAST detector model \n",
    "    layerNames = [\n",
    "            \"feature_fusion/Conv_7/Sigmoid\",\n",
    "            \"feature_fusion/concat_3\"]\n",
    "    \n",
    "    # load the pre-trained EAST text detector\n",
    "    net = cv2.dnn.readNet(east_decorator)\n",
    "\n",
    "    # construct a blob from the image \n",
    "    blob = cv2.dnn.blobFromImage(image, 1.0, (frame_size, frame_size),\n",
    "            (123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    (scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "    (numRows, numCols) = scores.shape[2:4]\n",
    "    rects = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over the number of rows\n",
    "    for y in range(0, numRows):\n",
    "        # extract the scores (probabilities)\n",
    "        scoresData = scores[0, 0, y]\n",
    "        xData0 = geometry[0, 0, y]\n",
    "        xData1 = geometry[0, 1, y]\n",
    "        xData2 = geometry[0, 2, y]\n",
    "        xData3 = geometry[0, 3, y]\n",
    "        anglesData = geometry[0, 4, y]\n",
    "\n",
    "        # loop over the number of columns\n",
    "        for x in range(0, numCols):\n",
    "\n",
    "                if scoresData[x] < min_confidence:\n",
    "                        continue\n",
    "\n",
    "                (offsetX, offsetY) = (x * 4.0, y * 4.0)\n",
    "\n",
    "                angle = anglesData[x]\n",
    "                cos = np.cos(angle)\n",
    "                sin = np.sin(angle)\n",
    "\n",
    "                h = xData0[x] + xData2[x]\n",
    "                w = xData1[x] + xData3[x]\n",
    "\n",
    "                endX = int(offsetX + (cos * xData1[x]) + (sin * xData2[x]))\n",
    "                endY = int(offsetY - (sin * xData1[x]) + (cos * xData2[x]))\n",
    "                startX = int(endX - w)\n",
    "                startY = int(endY - h)\n",
    "\n",
    "                rects.append((startX, startY, endX, endY))\n",
    "                confidences.append(scoresData[x])\n",
    "    \n",
    "    # apply non-maxima suppression \n",
    "    boxes = non_max_suppression(np.array(rects), probs=confidences)\n",
    "\n",
    "    # initialize the list of results\n",
    "    results = []\n",
    "\n",
    "    # loop over the bounding boxes\n",
    "    for (startX, startY, endX, endY) in boxes:\n",
    "\n",
    "            startX = int(startX * rW)\n",
    "            startY = int(startY * rH)\n",
    "            endX = int(endX * rW)\n",
    "            endY = int(endY * rH)\n",
    "            \n",
    "#             cv2.rectangle(img_copy, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "            dX = int((endX - startX) * padding)\n",
    "            dY = int((endY - startY) * padding)\n",
    "\n",
    "            startX = max(0, startX - dX)\n",
    "            startY = max(0, startY - dY)\n",
    "            endX = min(origW, endX + (dX * 2))\n",
    "            endY = min(origH, endY + (dY * 2))\n",
    "\n",
    "            # extract the actual padded ROI\n",
    "            cv2.rectangle(img_copy, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "            text = textRead(orig[startY:endY, startX:endX])\n",
    "\n",
    "            #cv2.rectangle(img_copy, (x+startX, y+startY), (x+endX, y+endY), (0, 255, 0), 2)\n",
    "\n",
    "            cv2.putText(img_copy, text, (startX, startY-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 255), 3)\n",
    "#             #return ([startX, startY, endX, endY], orig[startY:endY, startX:endX])\n",
    "\n",
    "# Loading image\n",
    "img = cv2.imread(file_name)\n",
    "img_copy = img.copy()\n",
    "textROI(img)\n",
    "# ([startX, startY, endX, endY], text_image) = textROI(img)\n",
    "\n",
    "# cv2.rectangle(img_copy, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "\n",
    "# show the output image\n",
    "cv2.imshow(\"OCR Text Recognition\", img_copy)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd400c",
   "metadata": {},
   "source": [
    "## 2. easyOCR (image)\n",
    "- text detection + text recognition 한번에 함\n",
    "- tesseract보다 정확도 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568948b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = 'test__.jpg'\n",
    "\n",
    "reader = easyocr.Reader(['en']) #한글은 'ko'\n",
    "result = reader.readtext(IMAGE_PATH)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_left = tuple(result[0][0][0])\n",
    "bottom_right = tuple(result[0][0][2])\n",
    "text = result[0][1]\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec80c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
    "img = cv2.putText(img,text,top_left, font, 2,(255,255,255),3,cv2.LINE_AA)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42baf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "spacer = 100\n",
    "for detection in result: \n",
    "    top_left = tuple(detection[0][0])\n",
    "    bottom_right = tuple(detection[0][2])\n",
    "    text = detection[1]\n",
    "    img = cv2.rectangle(img,top_left,bottom_right,(0,255,0),3)\n",
    "    img = cv2.putText(img,text,(20,spacer), font, 2,(0,255,0),2,cv2.LINE_AA)\n",
    "    spacer+=60\n",
    "    \n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ad205",
   "metadata": {},
   "source": [
    "## 3. easyOCR (real time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc9398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en', 'ko'], gpu=True) #gpu 안쓸거면 gpu=True 부분 그냥 지우기\n",
    "vid = cv2.VideoCapture(0)\n",
    "if not vid.isOpened:\n",
    "    print('Error opening video')\n",
    "    exit(0)\n",
    "skip_frame = True\n",
    "\n",
    "while(True):\n",
    "#     a = time.time()\n",
    "    ret, img = vid.read()\n",
    "    if img is None:\n",
    "        print('No more frame')\n",
    "        vid.release()\n",
    "        break\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    result = reader.readtext(gray)\n",
    "    text = \"\"\n",
    "    \n",
    "    for res in result:\n",
    "        text += res[1] + \" \"\n",
    "    cv2.putText(img, text, (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (50, 50, 255), 2)\n",
    "    \n",
    "#     ## FPS\n",
    "#     b = time.time()\n",
    "#     fps = 1/(b-a)\n",
    "#     cv2.line(img, (20, 25), (127, 25), [85, 45, 255], 30)\n",
    "#     cv2.putText(img, text, (50, 70), xv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 1, (50, 50, 255), 2)\n",
    "    cv2.imshow(\"result\", img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "#     print(fps)\n",
    "    print(text)\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
