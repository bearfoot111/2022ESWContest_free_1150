{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "858b64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-pythonNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "     ---------------------------------------- 35.6/35.6 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.21.2\n",
      "  Downloading numpy-1.23.1-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     ---------------------------------------- 14.6/14.6 MB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.23.1 opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654c2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/kernel:0' shape=(3, 3, 3, 32) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer1/conv2d/bias:0' shape=(32,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/kernel:0' shape=(3, 3, 32, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
      "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'layer2/conv2d/bias:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JinHyeokAn\\AppData\\Local\\Temp\\ipykernel_8336\\1173116780.py:32: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  point_3d = np.array(point_3d, dtype=np.float).reshape(-1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head up\n",
      "Head up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JinHyeokAn\\AppData\\Local\\Temp\\ipykernel_8336\\1173116780.py:188: RuntimeWarning: divide by zero encountered in int_scalars\n",
      "  m = (x2[1] - x1[1])/(x2[0] - x1[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head left\n",
      "Head down\n",
      "Head up\n",
      "Head up\n",
      "Head up\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head right\n",
      "Head right\n",
      "Head right\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head up\n",
      "Head up\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head up\n",
      "Head down\n",
      "Head down\n",
      "Head down\n",
      "Head up\n",
      "Head up\n",
      "Head up\n",
      "Head up\n",
      "Head up\n",
      "Head up\n",
      "Head right\n",
      "Head right\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n",
      "Head left\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jul 31 03:00:36 2020\n",
    "@author: hp\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from face_detector import get_face_detector, find_faces\n",
    "from face_landmarks import get_landmark_model, detect_marks\n",
    "\n",
    "def get_2d_points(img, rotation_vector, translation_vector, camera_matrix, val):\n",
    "    \"\"\"Return the 3D points present as 2D for making annotation box\"\"\"\n",
    "    point_3d = []\n",
    "    dist_coeffs = np.zeros((4,1))\n",
    "    rear_size = val[0]\n",
    "    rear_depth = val[1]\n",
    "    point_3d.append((-rear_size, -rear_size, rear_depth))\n",
    "    point_3d.append((-rear_size, rear_size, rear_depth))\n",
    "    point_3d.append((rear_size, rear_size, rear_depth))\n",
    "    point_3d.append((rear_size, -rear_size, rear_depth))\n",
    "    point_3d.append((-rear_size, -rear_size, rear_depth))\n",
    "    \n",
    "    front_size = val[2]\n",
    "    front_depth = val[3]\n",
    "    point_3d.append((-front_size, -front_size, front_depth))\n",
    "    point_3d.append((-front_size, front_size, front_depth))\n",
    "    point_3d.append((front_size, front_size, front_depth))\n",
    "    point_3d.append((front_size, -front_size, front_depth))\n",
    "    point_3d.append((-front_size, -front_size, front_depth))\n",
    "    point_3d = np.array(point_3d, dtype=np.float).reshape(-1, 3)\n",
    "    \n",
    "    # Map to 2d img points\n",
    "    (point_2d, _) = cv2.projectPoints(point_3d,\n",
    "                                      rotation_vector,\n",
    "                                      translation_vector,\n",
    "                                      camera_matrix,\n",
    "                                      dist_coeffs)\n",
    "    point_2d = np.int32(point_2d.reshape(-1, 2))\n",
    "    return point_2d\n",
    "\n",
    "def draw_annotation_box(img, rotation_vector, translation_vector, camera_matrix,\n",
    "                        rear_size=300, rear_depth=0, front_size=500, front_depth=400,\n",
    "                        color=(255, 255, 0), line_width=2):\n",
    "    \"\"\"\n",
    "    Draw a 3D anotation box on the face for head pose estimation\n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.unit8\n",
    "        Original Image.\n",
    "    rotation_vector : Array of float64\n",
    "        Rotation Vector obtained from cv2.solvePnP\n",
    "    translation_vector : Array of float64\n",
    "        Translation Vector obtained from cv2.solvePnP\n",
    "    camera_matrix : Array of float64\n",
    "        The camera matrix\n",
    "    rear_size : int, optional\n",
    "        Size of rear box. The default is 300.\n",
    "    rear_depth : int, optional\n",
    "        The default is 0.\n",
    "    front_size : int, optional\n",
    "        Size of front box. The default is 500.\n",
    "    front_depth : int, optional\n",
    "        Front depth. The default is 400.\n",
    "    color : tuple, optional\n",
    "        The color with which to draw annotation box. The default is (255, 255, 0).\n",
    "    line_width : int, optional\n",
    "        line width of lines drawn. The default is 2.\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "    \"\"\"\n",
    "    \n",
    "    rear_size = 1\n",
    "    rear_depth = 0\n",
    "    front_size = img.shape[1]\n",
    "    front_depth = front_size*2\n",
    "    val = [rear_size, rear_depth, front_size, front_depth]\n",
    "    point_2d = get_2d_points(img, rotation_vector, translation_vector, camera_matrix, val)\n",
    "    # # Draw all the lines\n",
    "    cv2.polylines(img, [point_2d], True, color, line_width, cv2.LINE_AA)\n",
    "    cv2.line(img, tuple(point_2d[1]), tuple(\n",
    "        point_2d[6]), color, line_width, cv2.LINE_AA)\n",
    "    cv2.line(img, tuple(point_2d[2]), tuple(\n",
    "        point_2d[7]), color, line_width, cv2.LINE_AA)\n",
    "    cv2.line(img, tuple(point_2d[3]), tuple(\n",
    "        point_2d[8]), color, line_width, cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "def head_pose_points(img, rotation_vector, translation_vector, camera_matrix):\n",
    "    \"\"\"\n",
    "    Get the points to estimate head pose sideways    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.unit8\n",
    "        Original Image.\n",
    "    rotation_vector : Array of float64\n",
    "        Rotation Vector obtained from cv2.solvePnP\n",
    "    translation_vector : Array of float64\n",
    "        Translation Vector obtained from cv2.solvePnP\n",
    "    camera_matrix : Array of float64\n",
    "        The camera matrix\n",
    "    Returns\n",
    "    -------\n",
    "    (x, y) : tuple\n",
    "        Coordinates of line to estimate head pose\n",
    "    \"\"\"\n",
    "    rear_size = 1\n",
    "    rear_depth = 0\n",
    "    front_size = img.shape[1]\n",
    "    front_depth = front_size*2\n",
    "    val = [rear_size, rear_depth, front_size, front_depth]\n",
    "    point_2d = get_2d_points(img, rotation_vector, translation_vector, camera_matrix, val)\n",
    "    y = (point_2d[5] + point_2d[8])//2\n",
    "    x = point_2d[2]\n",
    "    \n",
    "    return (x, y)\n",
    "    \n",
    "face_model = get_face_detector()\n",
    "landmark_model = get_landmark_model()\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, img = cap.read()\n",
    "size = img.shape\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "# 3D model points.\n",
    "model_points = np.array([\n",
    "                            (0.0, 0.0, 0.0),             # Nose tip\n",
    "                            (0.0, -330.0, -65.0),        # Chin\n",
    "                            (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                            (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                            (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                            (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "                        ])\n",
    "\n",
    "# Camera internals\n",
    "focal_length = size[1]\n",
    "center = (size[1]/2, size[0]/2)\n",
    "camera_matrix = np.array(\n",
    "                         [[focal_length, 0, center[0]],\n",
    "                         [0, focal_length, center[1]],\n",
    "                         [0, 0, 1]], dtype = \"double\"\n",
    "                         )\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    if ret == True:\n",
    "        faces = find_faces(img, face_model)\n",
    "        for face in faces:\n",
    "            marks = detect_marks(img, landmark_model, face)\n",
    "            # mark_detector.draw_marks(img, marks, color=(0, 255, 0))\n",
    "            image_points = np.array([\n",
    "                                    marks[30],     # Nose tip\n",
    "                                    marks[8],     # Chin\n",
    "                                    marks[36],     # Left eye left corner\n",
    "                                    marks[45],     # Right eye right corne\n",
    "                                    marks[48],     # Left Mouth corner\n",
    "                                    marks[54]      # Right mouth corner\n",
    "                                ], dtype=\"double\")\n",
    "            dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "            (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_UPNP)\n",
    "            \n",
    "            \n",
    "            # Project a 3D point (0, 0, 1000.0) onto the image plane.\n",
    "            # We use this to draw a line sticking out of the nose\n",
    "            \n",
    "            (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "            \n",
    "            for p in image_points:\n",
    "                cv2.circle(img, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "            \n",
    "            \n",
    "            p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "            p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "            x1, x2 = head_pose_points(img, rotation_vector, translation_vector, camera_matrix)\n",
    "\n",
    "            cv2.line(img, p1, p2, (0, 255, 255), 2)\n",
    "            cv2.line(img, tuple(x1), tuple(x2), (255, 255, 0), 2)\n",
    "            # for (x, y) in marks:\n",
    "            #     cv2.circle(img, (x, y), 4, (255, 255, 0), -1)\n",
    "            # cv2.putText(img, str(p1), p1, font, 1, (0, 255, 255), 1)\n",
    "            try:\n",
    "                m = (p2[1] - p1[1])/(p2[0] - p1[0])\n",
    "                ang1 = int(math.degrees(math.atan(m)))\n",
    "            except:\n",
    "                ang1 = 90\n",
    "                \n",
    "            try:\n",
    "                m = (x2[1] - x1[1])/(x2[0] - x1[0])\n",
    "                ang2 = int(math.degrees(math.atan(-1/m)))\n",
    "            except:\n",
    "                ang2 = 90\n",
    "                \n",
    "                # print('div by zero error')\n",
    "            if ang1 >= 48:\n",
    "                print('Head down')\n",
    "                cv2.putText(img, 'Head down', (30, 30), font, 2, (255, 255, 128), 3)\n",
    "            elif ang1 <= -48:\n",
    "                print('Head up')\n",
    "                cv2.putText(img, 'Head up', (30, 30), font, 2, (255, 255, 128), 3)\n",
    "             \n",
    "            if ang2 >= 48:\n",
    "                print('Head right')\n",
    "                cv2.putText(img, 'Head right', (90, 30), font, 2, (255, 255, 128), 3)\n",
    "            elif ang2 <= -48:\n",
    "                print('Head left')\n",
    "                cv2.putText(img, 'Head left', (90, 30), font, 2, (255, 255, 128), 3)\n",
    "            \n",
    "            cv2.putText(img, str(ang1), tuple(p1), font, 2, (128, 255, 255), 3)\n",
    "            cv2.putText(img, str(ang2), tuple(x1), font, 2, (255, 255, 128), 3)\n",
    "        cv2.imshow('img', img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4070d212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp310-cp310-win_amd64.whl (444.1 MB)\n",
      "     -------------------------------------- 444.1/444.1 MB 2.2 MB/s eta 0:00:00\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp310-cp310-win_amd64.whl (3.5 MB)\n",
      "     ---------------------------------------- 3.5/3.5 MB 2.8 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp310-cp310-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.5/895.5 kB 2.5 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "     -------------------------------------- 123.4/123.4 kB 2.4 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.2 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     ---------------------------------------- 14.2/14.2 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.23.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "     -------------------------------------- 438.7/438.7 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 1.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 3.3 MB/s eta 0:00:00\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 1.6/1.6 MB 3.6 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.3/93.3 kB 2.7 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.8/167.8 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.8/62.8 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.4/232.4 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     -------------------------------------- 155.3/155.3 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.9/139.9 kB 4.2 MB/s eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "     -------------------------------------- 160.2/160.2 kB 3.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jinhyeokan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ---------------------------------------- 77.1/77.1 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.5/151.5 kB 3.0 MB/s eta 0:00:00\n",
      "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, wrapt, wheel, werkzeug, urllib3, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, markdown, keras-preprocessing, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, absl-py, requests, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Running setup.py install for termcolor: started\n",
      "  Running setup.py install for termcolor: finished with status 'done'\n",
      "Successfully installed absl-py-1.2.0 astunparse-1.6.3 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.1.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.9.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.47.0 h5py-3.7.0 idna-3.3 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.4.1 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0 typing-extensions-4.3.0 urllib3-1.26.11 werkzeug-2.2.1 wheel-0.37.1 wrapt-1.14.1\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.2.1\n",
      "[notice] To update, run: C:\\Users\\JinHyeokAn\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe73c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
